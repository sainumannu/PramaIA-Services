{
  "name": "Multi-Provider LLM Comparison",
  "description": "Workflow per confrontare risposte di diversi provider LLM (OpenAI, Anthropic, Ollama) alla stessa query",
  "version": "1.0.0",
  "nodes": [
    {
      "id": "openai_generator",
      "type": "generic_llm_processor",
      "config": {
        "operation": "generate",
        "provider": "openai", 
        "model": "gpt-3.5-turbo",
        "temperature": 0.7,
        "max_tokens": 800,
        "response_format": "simple"
      },
      "inputs": {
        "prompt": "{user_query}",
        "system_prompt": "You are a helpful AI assistant. Provide clear and concise answers."
      }
    },
    {
      "id": "anthropic_generator",
      "type": "generic_llm_processor", 
      "config": {
        "operation": "generate",
        "provider": "anthropic",
        "model": "claude-3-5-sonnet-20241022",
        "temperature": 0.7,
        "max_tokens": 800,
        "response_format": "simple"
      },
      "inputs": {
        "prompt": "{user_query}",
        "system_prompt": "You are a helpful AI assistant. Provide thoughtful and nuanced answers."
      }
    },
    {
      "id": "ollama_generator",
      "type": "generic_llm_processor",
      "config": {
        "operation": "generate", 
        "provider": "ollama",
        "model": "llama2",
        "temperature": 0.7,
        "max_tokens": 800,
        "response_format": "simple"
      },
      "inputs": {
        "prompt": "{user_query}"
      }
    },
    {
      "id": "response_aggregator",
      "type": "generic_text_processor",
      "config": {
        "operation": "join",
        "join_strategy": "comparison_format",
        "separator": "\\n\\n=== COMPARISON REPORT ===\\n\\n"
      },
      "inputs": {
        "texts": [
          "**OpenAI Response:**\\n{openai_generator.output.response}",
          "**Anthropic Response:**\\n{anthropic_generator.output.response}",
          "**Ollama Response:**\\n{ollama_generator.output.response}"
        ]
      }
    },
    {
      "id": "comparison_analyzer",
      "type": "generic_llm_processor",
      "config": {
        "operation": "generate",
        "provider": "openai",
        "model": "gpt-4",
        "prompt_template": "Please analyze and compare these three AI responses to the question: \"{query}\"\\n\\n{responses}\\n\\nProvide a brief analysis comparing the quality, accuracy, and style of each response.",
        "temperature": 0.3,
        "max_tokens": 600,
        "response_format": "markdown"
      },
      "inputs": {
        "query": "{user_query}",
        "responses": "{response_aggregator.output.joined_text}"
      }
    }
  ],
  "connections": [
    {"from": "openai_generator", "to": "response_aggregator"},
    {"from": "anthropic_generator", "to": "response_aggregator"},
    {"from": "ollama_generator", "to": "response_aggregator"},
    {"from": "response_aggregator", "to": "comparison_analyzer"}
  ],
  "inputs": {
    "user_query": {
      "type": "string", 
      "description": "Domanda per confrontare i provider LLM",
      "required": true
    }
  },
  "outputs": {
    "openai_response": "{openai_generator.output.response}",
    "anthropic_response": "{anthropic_generator.output.response}",
    "ollama_response": "{ollama_generator.output.response}",
    "comparison_analysis": "{comparison_analyzer.output.response}",
    "full_report": "{response_aggregator.output.joined_text}"
  }
}